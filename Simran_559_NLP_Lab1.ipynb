{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EQus_9heFXws"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from gensim.utils import tokenize\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cRly3QdF32Y",
        "outputId": "2533afe3-df19-4f96-b3a8-3eeb8907171e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Tokenization\n",
        "Word tokenization breaks text into individual words or tokens, disregarding punctuation and special characters."
      ],
      "metadata": {
        "id": "tfCYUE8rKxEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2ScFYYZK1EC"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from gensim.utils import tokenize\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"Hey there! I'm Simran Basu, a passionate student currently pursuing my Master's in Artificial Intelligence and Machine Learning at Christ University in Bangalore ðŸŽ“. This semester, I'm diving deep into fascinating subjects like Natural Language Processing (NLP), Computer Vision (CV), Deep Learning, Augmented Reality/Virtual Reality (AR/VR), and the application of AI in Cognitive Sciences. I don't think it's just about studying; it's about understanding the intricate dynamics of these cutting-edge technologies ðŸ§ . Living in Bangalore, known as the Silicon Valley of India, offers an exciting environment for exploring the latest advancements in AI and ML. From innovative startups to leading tech companies, Bangalore provides ample opportunities to apply theoretical knowledge gained in the classroom to real-world projects. As I navigate through this enriching academic journey, I'm eager to delve into the intricacies of AI and ML, sharpen my skills, and contribute meaningfully to the field. Let's embark on this exciting adventure together! ðŸš€âœ¨\"\n",
        "\n",
        "# NLTK Word Tokenization\n",
        "nltk_tokens = word_tokenize(paragraph)\n",
        "\n",
        "# TextBlob Word Tokenization\n",
        "blob = TextBlob(paragraph)\n",
        "textblob_tokens = blob.words\n",
        "\n",
        "# spaCy Word Tokenization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(paragraph)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "\n",
        "# Gensim Word Tokenization\n",
        "gensim_tokens = list(tokenize(paragraph, lowercase=True))\n",
        "\n",
        "# Keras Word Tokenization\n",
        "keras_tokens = text_to_word_sequence(paragraph)\n",
        "\n",
        "print(\"NLTK Word Tokenization:\", nltk_tokens)\n",
        "print(\"TextBlob Word Tokenization:\", textblob_tokens) # TextBlob's tokenization provides a simple and effective way to break down text into its constituent words and punctuation marks.\n",
        "print(\"spaCy Word Tokenization:\", spacy_tokens) #spaCy tokenizer provides tokenization along with part-of-speech tagging, dependency parsing, and named entity recognition.\n",
        "print(\"Gensim Word Tokenization:\", gensim_tokens) #Gensim tokenizer focuses on creating tokens suitable for topic modeling and document similarity tasks.\n",
        "print(\"Keras Word Tokenization:\", keras_tokens) #Keras provides a simple tokenization method suitable for neural network-based text processing tasks."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEWeBOB-FxwP",
        "outputId": "c19e1d2b-b11a-4f64-d980-1f543669a626"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Word Tokenization: ['Hey', 'there', '!', 'I', \"'m\", 'Simran', 'Basu', ',', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'Master', \"'s\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“', '.', 'This', 'semester', ',', 'I', \"'m\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'CV', ')', ',', 'Deep', 'Learning', ',', 'Augmented', 'Reality/Virtual', 'Reality', '(', 'AR/VR', ')', ',', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences', '.', 'I', 'do', \"n't\", 'think', 'it', \"'s\", 'just', 'about', 'studying', ';', 'it', \"'s\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting-edge', 'technologies', 'ðŸ§ ', '.', 'Living', 'in', 'Bangalore', ',', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', ',', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML', '.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', ',', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real-world', 'projects', '.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', ',', 'I', \"'m\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', ',', 'sharpen', 'my', 'skills', ',', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', '.', 'Let', \"'s\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', '!', 'ðŸš€âœ¨']\n",
            "TextBlob Word Tokenization: ['Hey', 'there', 'I', \"'m\", 'Simran', 'Basu', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'Master', \"'s\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“', 'This', 'semester', 'I', \"'m\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', 'NLP', 'Computer', 'Vision', 'CV', 'Deep', 'Learning', 'Augmented', 'Reality/Virtual', 'Reality', 'AR/VR', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences', 'I', 'do', \"n't\", 'think', 'it', \"'s\", 'just', 'about', 'studying', 'it', \"'s\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting-edge', 'technologies', 'ðŸ§ ', 'Living', 'in', 'Bangalore', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real-world', 'projects', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', 'I', \"'m\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', 'sharpen', 'my', 'skills', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', 'Let', \"'s\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', 'ðŸš€âœ¨']\n",
            "spaCy Word Tokenization: ['Hey', 'there', '!', 'I', \"'m\", 'Simran', 'Basu', ',', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'Master', \"'s\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“', '.', 'This', 'semester', ',', 'I', \"'m\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'CV', ')', ',', 'Deep', 'Learning', ',', 'Augmented', 'Reality', '/', 'Virtual', 'Reality', '(', 'AR', '/', 'VR', ')', ',', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences', '.', 'I', 'do', \"n't\", 'think', 'it', \"'s\", 'just', 'about', 'studying', ';', 'it', \"'s\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting', '-', 'edge', 'technologies', 'ðŸ§ ', '.', 'Living', 'in', 'Bangalore', ',', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', ',', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML', '.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', ',', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real', '-', 'world', 'projects', '.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', ',', 'I', \"'m\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', ',', 'sharpen', 'my', 'skills', ',', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', '.', 'Let', \"'s\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', '!', 'ðŸš€', 'âœ¨']\n",
            "Gensim Word Tokenization: ['hey', 'there', 'i', 'm', 'simran', 'basu', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'master', 's', 'in', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'at', 'christ', 'university', 'in', 'bangalore', 'this', 'semester', 'i', 'm', 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'natural', 'language', 'processing', 'nlp', 'computer', 'vision', 'cv', 'deep', 'learning', 'augmented', 'reality', 'virtual', 'reality', 'ar', 'vr', 'and', 'the', 'application', 'of', 'ai', 'in', 'cognitive', 'sciences', 'i', 'don', 't', 'think', 'it', 's', 'just', 'about', 'studying', 'it', 's', 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting', 'edge', 'technologies', 'living', 'in', 'bangalore', 'known', 'as', 'the', 'silicon', 'valley', 'of', 'india', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'ai', 'and', 'ml', 'from', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', 'bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real', 'world', 'projects', 'as', 'i', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', 'i', 'm', 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'ai', 'and', 'ml', 'sharpen', 'my', 'skills', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', 'let', 's', 'embark', 'on', 'this', 'exciting', 'adventure', 'together']\n",
            "Keras Word Tokenization: ['hey', 'there', \"i'm\", 'simran', 'basu', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', \"master's\", 'in', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'at', 'christ', 'university', 'in', 'bangalore', 'ðŸŽ“', 'this', 'semester', \"i'm\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'natural', 'language', 'processing', 'nlp', 'computer', 'vision', 'cv', 'deep', 'learning', 'augmented', 'reality', 'virtual', 'reality', 'ar', 'vr', 'and', 'the', 'application', 'of', 'ai', 'in', 'cognitive', 'sciences', 'i', \"don't\", 'think', \"it's\", 'just', 'about', 'studying', \"it's\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting', 'edge', 'technologies', 'ðŸ§ ', 'living', 'in', 'bangalore', 'known', 'as', 'the', 'silicon', 'valley', 'of', 'india', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'ai', 'and', 'ml', 'from', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', 'bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real', 'world', 'projects', 'as', 'i', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', \"i'm\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'ai', 'and', 'ml', 'sharpen', 'my', 'skills', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', \"let's\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', 'ðŸš€âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Tokenization\n",
        "Sentence tokenization divides text into individual sentences based on punctuation and language-specific rules."
      ],
      "metadata": {
        "id": "4epzCMqzK7oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# NLTK Sentence Tokenization\n",
        "nltk_sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# spaCy Sentence Tokenization\n",
        "spacy_sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "print(\"NLTK Sentence Tokenization:\", nltk_sentences)\n",
        "print(\"spaCy Sentence Tokenization:\", spacy_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCzBwZKgGCjv",
        "outputId": "822f6a86-cf86-49d0-d3cb-495852bb1ab0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization: ['Hey there!', \"I'm Simran Basu, a passionate student currently pursuing my Master's in Artificial Intelligence and Machine Learning at Christ University in Bangalore ðŸŽ“.\", \"This semester, I'm diving deep into fascinating subjects like Natural Language Processing (NLP), Computer Vision (CV), Deep Learning, Augmented Reality/Virtual Reality (AR/VR), and the application of AI in Cognitive Sciences.\", \"It's not just about studying; it's about understanding the intricate dynamics of these cutting-edge technologies ðŸ§ .\", 'Living in Bangalore, known as the Silicon Valley of India, offers an exciting environment for exploring the latest advancements in AI and ML.', 'From innovative startups to leading tech companies, Bangalore provides ample opportunities to apply theoretical knowledge gained in the classroom to real-world projects.', \"As I navigate through this enriching academic journey, I'm eager to delve into the intricacies of AI and ML, sharpen my skills, and contribute meaningfully to the field.\", \"Let's embark on this exciting adventure together!\", 'ðŸš€âœ¨']\n",
            "spaCy Sentence Tokenization: ['Hey there!', \"I'm Simran Basu, a passionate student currently pursuing my Master's in Artificial Intelligence and Machine Learning at Christ University in Bangalore ðŸŽ“.\", \"This semester, I'm diving deep into fascinating subjects like Natural Language Processing (NLP), Computer Vision (CV), Deep Learning, Augmented Reality/Virtual Reality (AR/VR), and the application of AI in Cognitive Sciences.\", \"It's not just about studying; it's about understanding the intricate dynamics of these cutting-edge technologies ðŸ§ .\", 'Living in Bangalore, known as the Silicon Valley of India, offers an exciting environment for exploring the latest advancements in AI and ML.', 'From innovative startups to leading tech companies, Bangalore provides ample opportunities to apply theoretical knowledge gained in the classroom to real-world projects.', \"As I navigate through this enriching academic journey, I'm eager to delve into the intricacies of AI and ML, sharpen my skills, and contribute meaningfully to the field.\", \"Let's embark on this exciting adventure together!\", 'ðŸš€', 'âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Punctuation tokenizer\n",
        "Punctuation-based tokenization splits text based on punctuation marks, treating them as separate tokens.\n",
        "\n"
      ],
      "metadata": {
        "id": "IbF08xdtLDZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import spacy\n",
        "\n",
        "\n",
        "text = \"Hey there! I'm Simran Basu, a passionate student currently pursuing my Master's in Artificial Intelligence and Machine Learning at Christ University in Bangalore ðŸŽ“. This semester, I'm diving deep into fascinating subjects like Natural Language Processing (NLP), Computer Vision (CV), Deep Learning, Augmented Reality/Virtual Reality (AR/VR), and the application of AI in Cognitive Sciences. I don't think it's just about studying; it's about understanding the intricate dynamics of these cutting-edge technologies ðŸ§ . Living in Bangalore, known as the Silicon Valley of India, offers an exciting environment for exploring the latest advancements in AI and ML. From innovative startups to leading tech companies, Bangalore provides ample opportunities to apply theoretical knowledge gained in the classroom to real-world projects. As I navigate through this enriching academic journey, I'm eager to delve into the intricacies of AI and ML, sharpen my skills, and contribute meaningfully to the field. Let's embark on this exciting adventure together! ðŸš€âœ¨\"\n",
        "\n",
        "# NLTK Punctuation-based Tokenizer\n",
        "punkt_tokenizer = WordPunctTokenizer()\n",
        "nltk_punkt_tokens = punkt_tokenizer.tokenize(text)\n",
        "print(\"NLTK Punctuation-based Tokenization:\", nltk_punkt_tokens)\n",
        "\n",
        "# spaCy Punctuation-based Tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "custom_tokenizer = nlp.tokenizer\n",
        "doc = custom_tokenizer(text)\n",
        "spacy_punct_tokens = [token.text for token in doc if token.is_punct or token.text in ['ðŸŽ“', 'ðŸ§ ', 'ðŸš€', 'âœ¨']]\n",
        "print(\"spaCy Punctuation-based Tokenization:\", spacy_punct_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut2ExE9yGFy-",
        "outputId": "c36d5aca-ffb4-4ce1-e168-5e96a1e3a121"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Punctuation-based Tokenization: ['Hey', 'there', '!', 'I', \"'\", 'm', 'Simran', 'Basu', ',', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'Master', \"'\", 's', 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“.', 'This', 'semester', ',', 'I', \"'\", 'm', 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(', 'NLP', '),', 'Computer', 'Vision', '(', 'CV', '),', 'Deep', 'Learning', ',', 'Augmented', 'Reality', '/', 'Virtual', 'Reality', '(', 'AR', '/', 'VR', '),', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences', '.', 'I', 'don', \"'\", 't', 'think', 'it', \"'\", 's', 'just', 'about', 'studying', ';', 'it', \"'\", 's', 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting', '-', 'edge', 'technologies', 'ðŸ§ .', 'Living', 'in', 'Bangalore', ',', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', ',', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML', '.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', ',', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real', '-', 'world', 'projects', '.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', ',', 'I', \"'\", 'm', 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', ',', 'sharpen', 'my', 'skills', ',', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', '.', 'Let', \"'\", 's', 'embark', 'on', 'this', 'exciting', 'adventure', 'together', '!', 'ðŸš€âœ¨']\n",
            "spaCy Punctuation-based Tokenization: ['!', ',', 'ðŸŽ“', '.', ',', '(', ')', ',', '(', ')', ',', ',', '/', '(', '/', ')', ',', '.', ';', '-', 'ðŸ§ ', '.', ',', ',', '.', ',', '-', '.', ',', ',', ',', '.', '!', 'ðŸš€', 'âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Treebank Word Tokenizer\n",
        "\n",
        "The Treebank tokenizer follows the conventions of the Penn Treebank corpus for tokenization, which includes handling of contractions and punctuation."
      ],
      "metadata": {
        "id": "bOYp5UvuLCRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "# NLTK Treebank Word tokenizer\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "nltk_treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(\"NLTK Treebank Word tokenizer:\", nltk_treebank_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPlc1xDtGGFe",
        "outputId": "2a067fb0-2d97-4a5f-e6dd-ac7a1cd636ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Treebank Word tokenizer: ['Hey', 'there', '!', 'I', \"'m\", 'Simran', 'Basu', ',', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', 'Master', \"'s\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“.', 'This', 'semester', ',', 'I', \"'m\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'CV', ')', ',', 'Deep', 'Learning', ',', 'Augmented', 'Reality/Virtual', 'Reality', '(', 'AR/VR', ')', ',', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences.', 'It', \"'s\", 'not', 'just', 'about', 'studying', ';', 'it', \"'s\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting-edge', 'technologies', 'ðŸ§ .', 'Living', 'in', 'Bangalore', ',', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', ',', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', ',', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real-world', 'projects.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', ',', 'I', \"'m\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', ',', 'sharpen', 'my', 'skills', ',', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field.', 'Let', \"'s\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', '!', 'ðŸš€âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tweet Tokenizer\n",
        "\n",
        "Tweet tokenizer is specifically designed to handle the unique characteristics of tweets, including hashtags, mentions, and emoji."
      ],
      "metadata": {
        "id": "HQehcS_PLR3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# NLTK Tweet Tokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "nltk_tweet_tokens = tweet_tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(\"NLTK Tweet Tokenizer:\", nltk_tweet_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIJA-CS-GI5-",
        "outputId": "eb1a6420-a9c2-421e-a5dc-c2c9c54ba1e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tweet Tokenizer: ['Hey', 'there', '!', \"I'm\", 'Simran', 'Basu', ',', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', \"Master's\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“', '.', 'This', 'semester', ',', \"I'm\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'CV', ')', ',', 'Deep', 'Learning', ',', 'Augmented', 'Reality', '/', 'Virtual', 'Reality', '(', 'AR', '/', 'VR', ')', ',', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences', '.', \"It's\", 'not', 'just', 'about', 'studying', ';', \"it's\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting-edge', 'technologies', 'ðŸ§ ', '.', 'Living', 'in', 'Bangalore', ',', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India', ',', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML', '.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies', ',', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real-world', 'projects', '.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey', ',', \"I'm\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML', ',', 'sharpen', 'my', 'skills', ',', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field', '.', \"Let's\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together', '!', 'ðŸš€', 'âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Word Expression Tokenizer\n",
        "\n",
        "Identifies and tokenizes multi-word expressions or phrases that are treated as single tokens."
      ],
      "metadata": {
        "id": "TNrbDIXhLa-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "\n",
        "# NLTK Multi-Word Expression Tokenizer\n",
        "mwe_tokenizer = MWETokenizer([('cosmic', 'forces'), ('celestial', 'language'), ('cosmic', 'dance')])\n",
        "mwe_tokens = mwe_tokenizer.tokenize(paragraph.split())\n",
        "\n",
        "print(\"NLTK Multi-Word Expression Tokenizer:\", mwe_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woJY1NYdGL0t",
        "outputId": "00696a6f-781d-454a-faee-86c626fbd467"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Multi-Word Expression Tokenizer: ['Hey', 'there!', \"I'm\", 'Simran', 'Basu,', 'a', 'passionate', 'student', 'currently', 'pursuing', 'my', \"Master's\", 'in', 'Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'at', 'Christ', 'University', 'in', 'Bangalore', 'ðŸŽ“.', 'This', 'semester,', \"I'm\", 'diving', 'deep', 'into', 'fascinating', 'subjects', 'like', 'Natural', 'Language', 'Processing', '(NLP),', 'Computer', 'Vision', '(CV),', 'Deep', 'Learning,', 'Augmented', 'Reality/Virtual', 'Reality', '(AR/VR),', 'and', 'the', 'application', 'of', 'AI', 'in', 'Cognitive', 'Sciences.', \"It's\", 'not', 'just', 'about', 'studying;', \"it's\", 'about', 'understanding', 'the', 'intricate', 'dynamics', 'of', 'these', 'cutting-edge', 'technologies', 'ðŸ§ .', 'Living', 'in', 'Bangalore,', 'known', 'as', 'the', 'Silicon', 'Valley', 'of', 'India,', 'offers', 'an', 'exciting', 'environment', 'for', 'exploring', 'the', 'latest', 'advancements', 'in', 'AI', 'and', 'ML.', 'From', 'innovative', 'startups', 'to', 'leading', 'tech', 'companies,', 'Bangalore', 'provides', 'ample', 'opportunities', 'to', 'apply', 'theoretical', 'knowledge', 'gained', 'in', 'the', 'classroom', 'to', 'real-world', 'projects.', 'As', 'I', 'navigate', 'through', 'this', 'enriching', 'academic', 'journey,', \"I'm\", 'eager', 'to', 'delve', 'into', 'the', 'intricacies', 'of', 'AI', 'and', 'ML,', 'sharpen', 'my', 'skills,', 'and', 'contribute', 'meaningfully', 'to', 'the', 'field.', \"Let's\", 'embark', 'on', 'this', 'exciting', 'adventure', 'together!', 'ðŸš€âœ¨']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJq_kw_hLebe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}